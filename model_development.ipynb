{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "original_data = pd.read_csv(\"D:/unh_sem_2/Distributed and Scalable Data engineering/final_project/data_files/rating.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (1.34.88)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from boto3) (0.10.1)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.88 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from boto3) (1.34.88)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from botocore<1.35.0,>=1.34.88->boto3) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4; python_version < \"3.10\" in c:\\users\\asus\\anaconda3\\lib\\site-packages (from botocore<1.35.0,>=1.34.88->boto3) (1.25.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.88->boto3) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>source_id</th>\n",
       "      <th>source_name</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>url_to_image</th>\n",
       "      <th>published_at</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "      <th>article</th>\n",
       "      <th>title_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81664</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forbes</td>\n",
       "      <td>Elizabeth Brownfield, Contributor, \\n Elizabet...</td>\n",
       "      <td>superstar chef yannick alléno brings refined f...</td>\n",
       "      <td>Now open in Mayfair at Four Seasons Hotel Lond...</td>\n",
       "      <td>https://www.forbes.com/sites/elizabethbrownfie...</td>\n",
       "      <td>https://imageio.forbes.com/specials-images/ima...</td>\n",
       "      <td>2023-11-01 03:27:21.000000</td>\n",
       "      <td>Pavyllon London, at Four Seasons Hotel London ...</td>\n",
       "      <td>Monaco</td>\n",
       "      <td>pavyllon london, at four seasons hotel london ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CNA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nice claim top spot in ligue 1 with late win a...</td>\n",
       "      <td>Nice moved into provisional first place in the...</td>\n",
       "      <td>https://www.channelnewsasia.com/sport/nice-cla...</td>\n",
       "      <td>https://onecms-res.cloudinary.com/image/upload...</td>\n",
       "      <td>2023-10-27 21:28:48.000000</td>\n",
       "      <td>Nice moved into provisional first place in the...</td>\n",
       "      <td>Monaco</td>\n",
       "      <td>nice moved into provisional first place in the...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81694</td>\n",
       "      <td>time</td>\n",
       "      <td>Time</td>\n",
       "      <td>Christina Larson / AP</td>\n",
       "      <td>amphibians are the world’s most vulnerable spe...</td>\n",
       "      <td>The world’s frogs, salamanders, newts, and oth...</td>\n",
       "      <td>https://time.com/6320467/amphibians-most-vulne...</td>\n",
       "      <td>https://api.time.com/wp-content/uploads/2023/1...</td>\n",
       "      <td>2023-10-04 17:36:18.000000</td>\n",
       "      <td>The worlds frogs, salamanders, newts and other...</td>\n",
       "      <td>Madagascar</td>\n",
       "      <td>the world’s frogs, salamanders, newts and othe...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Phys.Org</td>\n",
       "      <td>Sara Schmidt</td>\n",
       "      <td>image: rusty red waters in madagascar</td>\n",
       "      <td>Iron-rich sediment colors the red-orange water...</td>\n",
       "      <td>https://phys.org/news/2023-10-image-rusty-red-...</td>\n",
       "      <td>https://scx2.b-cdn.net/gfx/news/2023/image-rus...</td>\n",
       "      <td>2023-10-31 18:04:02.000000</td>\n",
       "      <td>Iron-rich sediment colors the red-orange water...</td>\n",
       "      <td>Madagascar</td>\n",
       "      <td>iron-rich sediment colors the red-orange water...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81703</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Digital Trends</td>\n",
       "      <td>Jason Struss</td>\n",
       "      <td>everything leaving max (formerly hbo max) in n...</td>\n",
       "      <td>From Gangs of London to Fear the Walking Dead ...</td>\n",
       "      <td>https://www.digitaltrends.com/movies/everythin...</td>\n",
       "      <td>https://www.digitaltrends.com/wp-content/uploa...</td>\n",
       "      <td>2023-10-23 23:09:18.000000</td>\n",
       "      <td>Everything ends. No, I’m not having an existen...</td>\n",
       "      <td>Madagascar</td>\n",
       "      <td>everything ends. no, i’m not having an existen...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id source_id     source_name  \\\n",
       "0       81664       NaN          Forbes   \n",
       "1       81667       NaN             CNA   \n",
       "2       81694      time            Time   \n",
       "3       81695       NaN        Phys.Org   \n",
       "4       81703       NaN  Digital Trends   \n",
       "\n",
       "                                              author  \\\n",
       "0  Elizabeth Brownfield, Contributor, \\n Elizabet...   \n",
       "1                                                NaN   \n",
       "2                              Christina Larson / AP   \n",
       "3                                       Sara Schmidt   \n",
       "4                                       Jason Struss   \n",
       "\n",
       "                                               title  \\\n",
       "0  superstar chef yannick alléno brings refined f...   \n",
       "1  nice claim top spot in ligue 1 with late win a...   \n",
       "2  amphibians are the world’s most vulnerable spe...   \n",
       "3              image: rusty red waters in madagascar   \n",
       "4  everything leaving max (formerly hbo max) in n...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Now open in Mayfair at Four Seasons Hotel Lond...   \n",
       "1  Nice moved into provisional first place in the...   \n",
       "2  The world’s frogs, salamanders, newts, and oth...   \n",
       "3  Iron-rich sediment colors the red-orange water...   \n",
       "4  From Gangs of London to Fear the Walking Dead ...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.forbes.com/sites/elizabethbrownfie...   \n",
       "1  https://www.channelnewsasia.com/sport/nice-cla...   \n",
       "2  https://time.com/6320467/amphibians-most-vulne...   \n",
       "3  https://phys.org/news/2023-10-image-rusty-red-...   \n",
       "4  https://www.digitaltrends.com/movies/everythin...   \n",
       "\n",
       "                                        url_to_image  \\\n",
       "0  https://imageio.forbes.com/specials-images/ima...   \n",
       "1  https://onecms-res.cloudinary.com/image/upload...   \n",
       "2  https://api.time.com/wp-content/uploads/2023/1...   \n",
       "3  https://scx2.b-cdn.net/gfx/news/2023/image-rus...   \n",
       "4  https://www.digitaltrends.com/wp-content/uploa...   \n",
       "\n",
       "                 published_at  \\\n",
       "0  2023-11-01 03:27:21.000000   \n",
       "1  2023-10-27 21:28:48.000000   \n",
       "2  2023-10-04 17:36:18.000000   \n",
       "3  2023-10-31 18:04:02.000000   \n",
       "4  2023-10-23 23:09:18.000000   \n",
       "\n",
       "                                             content    category  \\\n",
       "0  Pavyllon London, at Four Seasons Hotel London ...      Monaco   \n",
       "1  Nice moved into provisional first place in the...      Monaco   \n",
       "2  The worlds frogs, salamanders, newts and other...  Madagascar   \n",
       "3  Iron-rich sediment colors the red-orange water...  Madagascar   \n",
       "4  Everything ends. No, I’m not having an existen...  Madagascar   \n",
       "\n",
       "                                             article title_sentiment  \n",
       "0  pavyllon london, at four seasons hotel london ...         Neutral  \n",
       "1  nice moved into provisional first place in the...        Positive  \n",
       "2  the world’s frogs, salamanders, newts and othe...        Negative  \n",
       "3  iron-rich sediment colors the red-orange water...         Neutral  \n",
       "4  everything ends. no, i’m not having an existen...         Neutral  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "original_data = original_data.drop(columns=[\"article_id\", \"source_id\", \"source_name\", \"author\", \"description\", \"url\", \"url_to_image\", \"published_at\", \"content\", \"category\", \"article\"])\n",
    "original_data = original_data.drop_duplicates(subset=['title'], keep='first')\n",
    "original_data = original_data.dropna(subset=['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neutral     39202\n",
       "Negative     8505\n",
       "Positive     5747\n",
       "Name: title_sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data[\"title_sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_rows = original_data[original_data['title_sentiment'] == 'Neutral']\n",
    "neutral_subset = neutral_rows.head(6000)\n",
    "positive_rows = original_data[original_data['title_sentiment'] == 'Positive']\n",
    "negative_rows = original_data[original_data['title_sentiment'] == 'Negative']\n",
    "data = pd.concat([neutral_subset, positive_rows, negative_rows], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Negative    8505\n",
       "Neutral     6000\n",
       "Positive    5747\n",
       "Name: title_sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"title_sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['title', 'title_sentiment'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "⚠ Restart to reload dependencies\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "spacy.cli.download(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Pre-processing\n",
    "\n",
    "Pre-processing is an essential task in Natural Language Processing (NLP) to prepare text data for training. It converts an input of raw text into cleansed tokens as single words or characters. The main pre-processing methods are summarized below:\n",
    "\n",
    "1.Tokenizing: Splits words into tokens\n",
    "\n",
    "2.Lemmatizing: Breaks words into their root format\n",
    "\n",
    "3.Removal of stop words: Takes off unnecessary words such as \"the,\" \"he,\" \"she,\" etc.\n",
    "\n",
    "4.Removal of punctuations: Takes off unessential word elements such as comma, period, brackets, parenthesis, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "<ipython-input-11-1c3dfda6a5bd>:23: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  tokenized_text = [[nlp(i.lower().strip())] for i in tqdm(raw_text)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b536b9b33f347619bc78878022a71c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20252.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-1c3dfda6a5bd>:29: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for doc in tqdm(tokenized_text):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae52f83d14e4aa7bb0162383edb98f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20252.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nltk\n",
    "import nltk.tokenize\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def preparation_text_data(data):\n",
    "    \"\"\"\n",
    "    This pipeline prepares the text data, conducting the following steps:\n",
    "    1) Tokenization\n",
    "    2) Lemmatization\n",
    "    4) Removal of stopwords\n",
    "    5) Removal of punctuation\n",
    "    \"\"\"\n",
    "    # initialize spacy object\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    # select raw text\n",
    "    raw_text = data.title.values.tolist()\n",
    "    # tokenize\n",
    "    tokenized_text = [[nlp(i.lower().strip())] for i in tqdm(raw_text)]\n",
    "    #define the punctuations and stop words\n",
    "    punc = string.punctuation\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    #lemmatize, remove stopwords and punctuationd\n",
    "    corpus = []\n",
    "    for doc in tqdm(tokenized_text):\n",
    "        corpus.append([word.lemma_ for word in doc[0] if (word.lemma_ not in stop_words and word.lemma_ not in punc)])\n",
    "    # add prepared data to df\n",
    "    data[\"title\"] = corpus\n",
    "    return data\n",
    "\n",
    "data =  preparation_text_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Label Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_mapping = {\n",
    "    \"Negative\": 0,\n",
    "    \"Neutral\": 1,\n",
    "    \"Positive\": 2\n",
    "}\n",
    "\n",
    "mask = data['title_sentiment'].isin([\"Negative\", \"Neutral\", \"Positive\"])\n",
    "\n",
    "# Map the numerical predictions to human-readable labels only for the selected values\n",
    "data.loc[mask, 'title_sentiment'] = data.loc[mask, 'title_sentiment'].map(sentiment_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Representation\n",
    "\n",
    "The second step involves transforming text data into meaningful vectors that can be understood by the ML model. I applied the TF-IDF (Term Frequency(TF) — Inverse Dense Frequency(IDF)), which creates weighted representations for input data based on the word occurrences in the entire corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20252, 21563)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "\n",
    "def text_representation(data):\n",
    "  data['title'] = data['title'].apply(lambda text: \" \".join(set(text)))\n",
    "  X_tfidf = tfidf_vect.fit_transform(data['title'])\n",
    "  print(X_tfidf.shape)\n",
    "  #print(tfidf_vect.get_feature_names())\n",
    "  X_tfidf = pd.DataFrame(X_tfidf.toarray())\n",
    "  return X_tfidf#apply the TFIDV function\n",
    "\n",
    "\n",
    "X_tfidf = text_representation(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "At this stage, we are ready to build and train the ML Logistic Regression model. We split the dataset intotrain and test sets, fit the model, and predict on the data points. The model achieves an accuracy score of 75%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.87      0.82      2794\n",
      "           1       0.68      0.61      0.64      1958\n",
      "           2       0.80      0.75      0.78      1932\n",
      "\n",
      "    accuracy                           0.76      6684\n",
      "   macro avg       0.75      0.74      0.75      6684\n",
      "weighted avg       0.76      0.76      0.76      6684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X= X_tfidf\n",
    "y = data['title_sentiment'].astype('int')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "clf= LogisticRegression()\n",
    "clf.fit(X_train,y_train)\n",
    "clf.score(X_test,y_test)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on new instance\n",
    "\n",
    "We can predict on new instance as shown below, we feed the model with a new headline and we predict the label which is negative in our example as we are conveying war and sanctions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment: 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Assuming you have a new text data point\n",
    "new_text = \"texas instruments breaks ground on new 300-mm semiconductor wafer fabrication plant in utah\"\n",
    "\n",
    "# Vectorize the new text using the same TF-IDF vectorizer used for training\n",
    "new_text_tfidf = tfidf_vect.transform([new_text])\n",
    "\n",
    "# Make predictions using the trained logistic regression model\n",
    "prediction = clf.predict(new_text_tfidf)\n",
    "\n",
    "# Print the prediction\n",
    "print(\"Predicted Sentiment:\", prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.joblib']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(clf, 'model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vect.joblib']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model to a file\n",
    "joblib.dump(clf, 'model.joblib')\n",
    "\n",
    "# Save the TF-IDF vectorizer to a file\n",
    "joblib.dump(tfidf_vect, 'tfidf_vect.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
